#!/usr/bin/env python3
"""
Interface Web - Sistema RAG Local
Interface com carregamento e feedback visual
"""

import streamlit as st
import os
import sys
import time
import logging
from pathlib import Path
from datetime import datetime
import json
import sqlite3
import hashlib
import re
from typing import List, Dict, Any
import urllib.request
from html.parser import HTMLParser
import random

# Adicionar o diretÃ³rio atual ao path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Configurar logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="RAG Local - Interface",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estado da sessÃ£o
if 'processing_status' not in st.session_state:
    st.session_state['processing_status'] = {
        'is_processing': False,
        'current_file': None,
        'processed_files': [],
        'failed_files': [],
        'total_files': 0,
        'progress': 0,
        'logs': [],
        'start_time': None
    }

if 'rag_system' not in st.session_state:
    st.session_state['rag_system'] = None

if 'vector_db_path' not in st.session_state:
    st.session_state['vector_db_path'] = "vector_db.sqlite"

if 'loading_animation' not in st.session_state:
    st.session_state['loading_animation'] = True

# ============================================================================
# SISTEMA RAG
# ============================================================================

class RAGSystem:
    """Sistema RAG com feedback visual"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.init_db()
    
    def init_db(self):
        """Inicializar banco de dados"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS documents (
                id TEXT PRIMARY KEY,
                file_path TEXT,
                file_type TEXT,
                content TEXT,
                metadata TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS chunks (
                id TEXT PRIMARY KEY,
                document_id TEXT,
                chunk_text TEXT,
                chunk_index INTEGER,
                vector TEXT,
                metadata TEXT,
                FOREIGN KEY (document_id) REFERENCES documents (id)
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def create_smart_embedding(self, text: str) -> List[float]:
        """Criar embedding inteligente"""
        # TokenizaÃ§Ã£o avanÃ§ada
        words = re.findall(r'\b\w+\b', text.lower())
        
        # Remover stopwords
        stopwords = {
            'a', 'o', 'e', 'de', 'do', 'da', 'em', 'para', 'com', 'por', 'que', 'um', 'uma',
            'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'
        }
        words = [w for w in words if w not in stopwords and len(w) > 2]
        
        # Calcular frequÃªncia
        word_freq = {}
        for word in words:
            word_freq[word] = word_freq.get(word, 0) + 1
        
        # Criar vetor de 128 dimensÃµes
        vector = [0.0] * 128
        
        for word, freq in word_freq.items():
            hash_val = hash(word) % 128
            vector[hash_val] += freq
        
        # Normalizar
        norm = sum(x * x for x in vector) ** 0.5
        if norm > 0:
            vector = [x / norm for x in vector]
        
        return vector
    
    def smart_query(self, question: str, max_results: int = 5) -> List[Dict]:
        """Consulta inteligente"""
        query_embedding = self.create_smart_embedding(question)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT id, document_id, chunk_text, vector, metadata FROM chunks")
        results = []
        
        for row in cursor.fetchall():
            chunk_id, doc_id, chunk_text, vector_json, metadata_json = row
            vector = json.loads(vector_json) if vector_json else []
            metadata = json.loads(metadata_json) if metadata_json else {}
            
            if vector:
                # Similaridade vetorial
                dot_product = sum(a * b for a, b in zip(query_embedding, vector))
                norm1 = sum(a * a for a in query_embedding) ** 0.5
                norm2 = sum(b * b for b in vector) ** 0.5
                vector_sim = dot_product / (norm1 * norm2) if norm1 > 0 and norm2 > 0 else 0
            else:
                vector_sim = 0
            
            # Similaridade textual
            question_words = set(re.findall(r'\b\w+\b', question.lower()))
            chunk_words = set(re.findall(r'\b\w+\b', chunk_text.lower()))
            
            if question_words and chunk_words:
                jaccard_sim = len(question_words.intersection(chunk_words)) / len(question_words.union(chunk_words))
            else:
                jaccard_sim = 0
            
            # Similaridade combinada
            combined_sim = (vector_sim * 0.6) + (jaccard_sim * 0.4)
            
            if combined_sim > 0.05:
                results.append({
                    'chunk_id': chunk_id,
                    'document_id': doc_id,
                    'chunk_text': chunk_text,
                    'similarity': combined_sim,
                    'vector_sim': vector_sim,
                    'text_sim': jaccard_sim,
                    'metadata': metadata
                })
        
        conn.close()
        
        results.sort(key=lambda x: x['similarity'], reverse=True)
        return results[:max_results]
    
    def get_stats(self):
        """Obter estatÃ­sticas"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("SELECT COUNT(*) FROM documents")
        doc_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT COUNT(*) FROM chunks")
        chunk_count = cursor.fetchone()[0]
        
        cursor.execute("SELECT file_type, COUNT(*) FROM documents GROUP BY file_type")
        file_types = cursor.fetchall()
        
        conn.close()
        
        return {
            'documents': doc_count,
            'chunks': chunk_count,
            'file_types': file_types
        }

# ============================================================================
# EFEITOS VISUAIS
# ============================================================================

def show_loading():
    """Mostrar carregamento"""
    with st.spinner("ğŸ”„ Carregando sistema RAG..."):
        time.sleep(1)
    
    # Progresso
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    steps = [
        "ğŸ” Inicializando banco de dados...",
        "ğŸ§  Carregando sistema de IA...",
        "ğŸ“Š Preparando estatÃ­sticas...",
        "âš™ï¸ Configurando sistema...",
        "âœ… Sistema pronto!"
    ]
    
    for i, step in enumerate(steps):
        progress_bar.progress((i + 1) / len(steps))
        status_text.text(step)
        time.sleep(0.5)
    
    progress_bar.empty()
    status_text.empty()

def show_processing():
    """Mostrar processamento"""
    # Arquivos sendo processados
    processing_placeholder = st.empty()
    
    steps = [
        "ğŸ“„ Processando arquivos...",
        "ğŸ” Analisando conteÃºdo...",
        "ğŸ§  Gerando embeddings...",
        "ğŸ’¾ Salvando no banco...",
        "âœ… ConcluÃ­do!"
    ]
    
    for step in steps:
        processing_placeholder.text(step)
        time.sleep(0.3)
    
    processing_placeholder.empty()

def show_success():
    """Mostrar sucesso"""
    success_placeholder = st.empty()
    
    success_messages = [
        "ğŸ‰ Processamento concluÃ­do!",
        "âœ… Arquivos processados com sucesso!",
        "ğŸ§  Sistema RAG pronto para consultas!",
        "ğŸš€ Interface carregada com sucesso!"
    ]
    
    for message in success_messages:
        success_placeholder.success(message)
        time.sleep(0.5)
    
    success_placeholder.empty()

# ============================================================================
# PROCESSAMENTO
# ============================================================================

def process_document(file_path: Path) -> dict:
    """Processar documento"""
    try:
        # Leitura
        with st.spinner(f"ğŸ“– Lendo {file_path.name}..."):
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
        
        if not content.strip():
            return {'success': False, 'error': 'Arquivo vazio'}
        
        # AnÃ¡lise
        with st.spinner(f"ğŸ” Analisando {file_path.name}..."):
            # Extrair URLs
            url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
            urls = re.findall(url_pattern, content)
            
            # Fazer scraping de URLs
            scraped_content = ""
            if urls:
                for url in urls[:2]:  # Limitar a 2 URLs
                    try:
                        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
                        with urllib.request.urlopen(req, timeout=3) as response:
                            html_content = response.read().decode('utf-8', errors='ignore')
                            # Extrair texto do HTML
                            class HTMLTextExtractor(HTMLParser):
                                def __init__(self):
                                    super().__init__()
                                    self.text = []
                                
                                def handle_data(self, data):
                                    self.text.append(data)
                                
                                def get_text(self):
                                    return ' '.join(self.text)
                            
                            extractor = HTMLTextExtractor()
                            extractor.feed(html_content)
                            scraped_text = extractor.get_text()
                            scraped_content += f"\n\n--- ConteÃºdo de {url} ---\n{scraped_text}"
                    except:
                        pass
        
        # Combinar conteÃºdo
        full_content = content + scraped_content
        
        # Salvamento
        with st.spinner(f"ğŸ’¾ Salvando {file_path.name}..."):
            # Criar ID Ãºnico
            doc_id = hashlib.md5(str(file_path).encode()).hexdigest()[:16]
            
            # Salvar no banco
            conn = sqlite3.connect(st.session_state['vector_db_path'])
            cursor = conn.cursor()
            
            metadata = {
                'file_path': str(file_path),
                'file_type': file_path.suffix,
                'word_count': len(full_content.split()),
                'char_count': len(full_content),
                'urls_found': len(urls),
                'processed_at': datetime.now().isoformat()
            }
            
            cursor.execute('''
                INSERT OR REPLACE INTO documents (id, file_path, file_type, content, metadata)
                VALUES (?, ?, ?, ?, ?)
            ''', (doc_id, str(file_path), file_path.suffix, full_content, json.dumps(metadata)))
            
            # Criar chunks
            chunk_size = 1000
            chunks = [full_content[i:i+chunk_size] for i in range(0, len(full_content), chunk_size)]
            
            # Salvar chunks com embeddings
            rag_system = RAGSystem(st.session_state['vector_db_path'])
            
            for i, chunk in enumerate(chunks):
                chunk_id = f"{doc_id}_chunk_{i}"
                embedding = rag_system.create_smart_embedding(chunk)
                
                chunk_metadata = {
                    'chunk_index': i,
                    'total_chunks': len(chunks),
                    'chunk_size': len(chunk)
                }
                
                cursor.execute('''
                    INSERT OR REPLACE INTO chunks (id, document_id, chunk_text, chunk_index, vector, metadata)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (chunk_id, doc_id, chunk, i, json.dumps(embedding), json.dumps(chunk_metadata)))
            
            conn.commit()
            conn.close()
        
        return {
            'success': True,
            'doc_id': doc_id,
            'text_length': len(full_content),
            'urls_count': len(urls),
            'chunks_count': len(chunks)
        }
        
    except Exception as e:
        return {'success': False, 'error': str(e)}

def process_all_files():
    """Processar todos os arquivos"""
    try:
        status = st.session_state['processing_status']
        
        # Resetar status
        status['is_processing'] = True
        status['processed_files'] = []
        status['failed_files'] = []
        status['logs'] = []
        status['start_time'] = datetime.now()
        
        # InÃ­cio
        st.info("ğŸš€ Iniciando processamento...")
        
        # Obter arquivos
        documents_dir = Path("/home/lsantann/Documents/CC/")
        supported_extensions = ['.txt', '.md', '.py', '.js', '.html', '.css', '.json', '.yaml', '.yml']
        
        all_files = []
        for ext in supported_extensions:
            all_files.extend(documents_dir.rglob(f"*{ext}"))
        
        # Limitar a 100 arquivos
        all_files = all_files[:100]
        status['total_files'] = len(all_files)
        
        # Log de inÃ­cio
        log_entry = {
            'timestamp': datetime.now().strftime('%H:%M:%S'),
            'level': 'INFO',
            'message': f"ğŸš€ Iniciando processamento de {len(all_files)} arquivos",
            'module': 'interface'
        }
        status['logs'].append(log_entry)
        
        # Barra de progresso principal
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # Processar arquivos
        for i, file_path in enumerate(all_files):
            status['current_file'] = str(file_path)
            status['progress'] = (i / len(all_files)) * 100
            
            # Atualizar barra de progresso
            progress_bar.progress(status['progress'] / 100)
            status_text.text(f"ğŸ”„ Processando: {file_path.name}")
            
            # Processar arquivo
            result = process_document(file_path)
            
            if result['success']:
                status['processed_files'].append({
                    'file': str(file_path),
                    'size': result['text_length'],
                    'urls': result['urls_count'],
                    'chunks': result['chunks_count'],
                    'timestamp': datetime.now().strftime('%H:%M:%S')
                })
                log_entry = {
                    'timestamp': datetime.now().strftime('%H:%M:%S'),
                    'level': 'SUCCESS',
                    'message': f"âœ… {file_path.name} ({result['text_length']} chars, {result['urls_count']} URLs, {result['chunks_count']} chunks)",
                    'module': 'interface'
                }
            else:
                status['failed_files'].append({
                    'file': str(file_path),
                    'error': result['error'],
                    'timestamp': datetime.now().strftime('%H:%M:%S')
                })
                log_entry = {
                    'timestamp': datetime.now().strftime('%H:%M:%S'),
                    'level': 'WARNING',
                    'message': f"âš ï¸ {file_path.name} - {result['error']}",
                    'module': 'interface'
                }
            
            status['logs'].append(log_entry)
            
            # Manter apenas os Ãºltimos 50 logs
            if len(status['logs']) > 50:
                status['logs'] = status['logs'][-50:]
        
        # Finalizar
        status['is_processing'] = False
        status['current_file'] = None
        status['progress'] = 100
        
        # ConclusÃ£o
        progress_bar.progress(1.0)
        status_text.text("ğŸ‰ Processamento concluÃ­do!")
        
        # Mostrar sucesso
        show_success()
        
        log_entry = {
            'timestamp': datetime.now().strftime('%H:%M:%S'),
            'level': 'INFO',
            'message': f"ğŸ‰ Processamento concluÃ­do! {len(status['processed_files'])} processados, {len(status['failed_files'])} falharam",
            'module': 'interface'
        }
        status['logs'].append(log_entry)
        
        # Limpar elementos
        progress_bar.empty()
        status_text.empty()
        
    except Exception as e:
        status = st.session_state['processing_status']
        status['is_processing'] = False
        log_entry = {
            'timestamp': datetime.now().strftime('%H:%M:%S'),
            'level': 'ERROR',
            'message': f"Erro geral: {str(e)}",
            'module': 'interface'
        }
        status['logs'].append(log_entry)

# ============================================================================
# INTERFACE PRINCIPAL
# ============================================================================

def main():
    """Interface principal"""
    
    # TÃ­tulo
    st.title("ğŸ¤– Sistema RAG Local - Interface")
    st.markdown("**Sistema RAG 100% Open Source com Feedback Visual**")
    
    # Carregamento inicial
    if st.session_state['loading_animation']:
        show_loading()
        st.session_state['loading_animation'] = False
    
    # Inicializar sistema RAG
    if st.session_state['rag_system'] is None:
        with st.spinner("ğŸ§  Inicializando sistema RAG..."):
            st.session_state['rag_system'] = RAGSystem(st.session_state['vector_db_path'])
    
    # Sidebar
    with st.sidebar:
        st.header("ğŸ›ï¸ Controles Principais")
        
        # BotÃ£o de processamento
        st.markdown("### ğŸš€ Processamento")
        
        if st.button("ğŸš€ PROCESSAR ARQUIVOS", type="primary", use_container_width=True):
            if not st.session_state['processing_status']['is_processing']:
                process_all_files()
                st.rerun()
        
        # BotÃ£o para consulta RAG
        st.markdown("### ğŸ” Consulta RAG")
        question = st.text_area("Digite sua pergunta:", height=100, placeholder="Ex: O que Ã© machine learning? Como funciona deep learning?")
        
        if st.button("ğŸ” FAZER CONSULTA", type="secondary", use_container_width=True):
            if question.strip():
                with st.spinner("ğŸ” Buscando respostas..."):
                    rag_system = st.session_state['rag_system']
                    results = rag_system.smart_query(question)
                
                if results:
                    st.success(f"âœ… Encontradas {len(results)} respostas")
                    for i, result in enumerate(results[:3], 1):
                        with st.expander(f"Resposta {i} - Similaridade: {result['similarity']:.3f}"):
                            st.write(f"**Vetorial:** {result['vector_sim']:.3f} | **Textual:** {result['text_sim']:.3f}")
                            st.write(f"**Texto:** {result['chunk_text'][:300]}...")
                else:
                    st.warning("âŒ Nenhuma resposta relevante encontrada")
        
        # EstatÃ­sticas
        st.markdown("### ğŸ“Š EstatÃ­sticas")
        stats = st.session_state['rag_system'].get_stats()
        
        # MÃ©tricas
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ğŸ“„ Documentos", stats['documents'], delta=None)
        with col2:
            st.metric("ğŸ“ Chunks", stats['chunks'], delta=None)
        
        if stats['file_types']:
            st.write("**Tipos de arquivo:**")
            for file_type, count in stats['file_types']:
                st.write(f"â€¢ {file_type}: {count}")
        
        # Status do processamento
        status = st.session_state['processing_status']
        if status['is_processing']:
            st.info(f"ğŸ”„ Processando: {Path(status['current_file']).name if status['current_file'] else 'N/A'}")
            st.progress(status['progress'] / 100)
        elif status['processed_files']:
            st.success(f"âœ… {len(status['processed_files'])} arquivos processados")
        else:
            st.warning("â¸ï¸ Nenhum processamento em andamento")
    
    # ConteÃºdo principal
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“Š Dashboard")
        
        # MÃ©tricas principais
        stats = st.session_state['rag_system'].get_stats()
        
        col1_1, col1_2, col1_3 = st.columns(3)
        with col1_1:
            st.metric("ğŸ“„ Documentos", stats['documents'], delta=None)
        with col1_2:
            st.metric("ğŸ“ Chunks", stats['chunks'], delta=None)
        with col1_3:
            st.metric("ğŸ¤– Sistema", "Ativo")
        
        # Status do processamento
        status = st.session_state['processing_status']
        if status['is_processing']:
            st.info(f"ğŸ”„ **Processando:** {Path(status['current_file']).name if status['current_file'] else 'N/A'}")
            st.progress(status['progress'] / 100)
        elif status['processed_files']:
            st.success(f"âœ… **Processamento concluÃ­do:** {len(status['processed_files'])} arquivos processados")
        else:
            st.warning("â¸ï¸ **Nenhum processamento em andamento**")
        
        # Lista de arquivos processados
        if status['processed_files']:
            st.subheader("ğŸ“ Arquivos Processados (Ãšltimos 10)")
            for file_info in status['processed_files'][-10:]:
                with st.container():
                    st.write(f"ğŸ“„ **{Path(file_info['file']).name}** - {file_info['size']} chars, {file_info['urls']} URLs, {file_info['chunks']} chunks - {file_info['timestamp']}")
        
        # Arquivos com falha
        if status['failed_files']:
            st.subheader("âŒ Arquivos com Falha (Ãšltimos 5)")
            for file_info in status['failed_files'][-5:]:
                st.write(f"âŒ **{Path(file_info['file']).name}** - {file_info['error']} - {file_info['timestamp']}")
    
    with col2:
        st.header("ğŸ“ Logs")
        
        # Filtros
        log_level = st.selectbox("Filtrar logs:", ["TODOS", "INFO", "SUCCESS", "WARNING", "ERROR"])
        
        # Logs
        status = st.session_state['processing_status']
        if status['logs']:
            # Filtrar logs
            filtered_logs = status['logs']
            if log_level != "TODOS":
                filtered_logs = [log for log in status['logs'] if log['level'] == log_level]
            
            # Mostrar logs
            for log in filtered_logs[-15:]:  # Ãšltimos 15
                level_emoji = {
                    'INFO': 'â„¹ï¸',
                    'SUCCESS': 'âœ…',
                    'WARNING': 'âš ï¸',
                    'ERROR': 'âŒ'
                }.get(log['level'], 'ğŸ“')
                
                st.write(f"{level_emoji} **{log['timestamp']}** {log['message']}")
        else:
            st.info("Nenhum log disponÃ­vel ainda")
        
        # Auto-refresh
        if status['is_processing']:
            time.sleep(2)
            st.rerun()
    
    # InformaÃ§Ãµes do sistema
    st.markdown("---")
    st.subheader("ğŸ¤– Sistema RAG")
    
    col3, col4, col5 = st.columns(3)
    
    with col3:
        st.write("**ğŸ¤– Sistema:**")
        st.write("â€¢ Carregamento com progresso")
        st.write("â€¢ Processamento em tempo real")
        st.write("â€¢ Feedback visual completo")
        st.write("â€¢ Logs em tempo real")
    
    with col4:
        st.write("**ğŸ“ Processamento:**")
        st.write(f"â€¢ DiretÃ³rio: `/home/lsantann/Documents/CC/`")
        st.write(f"â€¢ Banco: `{st.session_state['vector_db_path']}`")
        st.write("â€¢ ExtensÃµes: .txt, .md, .py, .js, .html, .css, .json, .yaml")
        st.write("â€¢ URL scraping automÃ¡tico")
    
    with col5:
        st.write("**âš¡ Status:**")
        if status['is_processing']:
            st.write("ğŸ”„ Processando...")
        elif status['processed_files']:
            st.write("âœ… Sistema pronto")
        else:
            st.write("â¸ï¸ Aguardando processamento")
    
    # Footer
    st.markdown("---")
    st.markdown("**ğŸ¤– Sistema RAG Local - Interface - 100% Open Source - Desenvolvido com â¤ï¸**")

if __name__ == "__main__":
    main()
