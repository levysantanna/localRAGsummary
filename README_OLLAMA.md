# ü§ñ Sistema RAG com Ollama

Interface Streamlit com integra√ß√£o completa ao Ollama para resultados de alta qualidade.

## ‚ú® Caracter√≠sticas

- **Seletor de Modelo**: Escolha entre diferentes modelos Ollama
- **Integra√ß√£o Ollama**: Respostas de alta qualidade usando LLMs locais
- **Busca Inteligente**: Busca sem√¢ntica em documentos processados
- **Gera√ß√£o de Resumos**: Resumos autom√°ticos com contexto relevante
- **Interface Intuitiva**: Controles claros e feedback visual

## üöÄ Instala√ß√£o R√°pida

```bash
# 1. Executar script de configura√ß√£o
./setup_ollama.sh

# 2. Iniciar interface
cd /home/lsantann/dev/localRAGsummary
source venv/bin/activate
streamlit run interface_ollama.py --server.port 8511
```

## üß† Modelos Dispon√≠veis

### Modelos Recomendados:
- **llama3.2** - Melhor equil√≠brio qualidade/velocidade
- **llama3.1** - Vers√£o anterior est√°vel
- **mistral** - Alternativa eficiente
- **codellama** - Especializado em c√≥digo

### Modelos Especializados:
- **phi3** - Microsoft Phi-3
- **gemma** - Google Gemma
- **qwen** - Alibaba Qwen
- **deepseek-coder** - Especializado em programa√ß√£o

## üìã Como Usar

### 1. Configura√ß√£o Inicial
- Acesse a interface em `http://localhost:8511`
- Verifique se o Ollama est√° conectado (‚úÖ verde)
- Selecione o modelo desejado no sidebar

### 2. Fazer Consultas
- Digite sua pergunta no campo de texto
- Clique em "üîç Buscar" para encontrar documentos relevantes
- Clique em "üìù Gerar Resumo" para criar resumo com IA

### 3. Resumos Salvos
- Todos os resumos s√£o salvos automaticamente
- Visualize resumos anteriores na se√ß√£o "üìö Resumos Salvos"
- Cada resumo inclui metadados e timestamp

## üîß Configura√ß√µes Avan√ßadas

### Modelos Personalizados
```bash
# Baixar modelo espec√≠fico
ollama pull nome-do-modelo

# Listar modelos dispon√≠veis
ollama list

# Remover modelo
ollama rm nome-do-modelo
```

### Configura√ß√£o de Performance
- **Temperature**: 0.7 (criatividade)
- **Top-p**: 0.9 (diversidade)
- **Max Tokens**: 2048 (tamanho da resposta)

## üìä Recursos da Interface

### Sidebar
- **Status Ollama**: Verifica√ß√£o de conex√£o
- **Seletor de Modelo**: Escolha do modelo ativo
- **Estat√≠sticas**: Contadores de arquivos
- **Configura√ß√µes**: Caminhos do sistema

### √Årea Principal
- **Campo de Consulta**: Input para perguntas
- **Bot√µes de A√ß√£o**: Buscar e Gerar Resumo
- **Resultados**: Lista de documentos encontrados
- **Resumo Gerado**: Output da IA

### Se√ß√£o de Resumos
- **Lista de Resumos**: √öltimos 5 resumos gerados
- **Preview**: Visualiza√ß√£o r√°pida do conte√∫do
- **Metadados**: Data, tamanho, arquivo

## üõ†Ô∏è Solu√ß√£o de Problemas

### Ollama n√£o conecta
```bash
# Verificar se est√° rodando
curl http://localhost:11434/api/tags

# Iniciar servidor
ollama serve

# Verificar logs
journalctl -u ollama
```

### Modelo n√£o carrega
```bash
# Verificar modelos dispon√≠veis
ollama list

# Baixar modelo espec√≠fico
ollama pull llama3.2

# Verificar espa√ßo em disco
df -h
```

### Interface n√£o abre
```bash
# Verificar porta
netstat -tlnp | grep 8511

# Matar processo
pkill -f "streamlit run interface_ollama.py"

# Reiniciar
streamlit run interface_ollama.py --server.port 8511
```

## üìà Melhorias de Qualidade

### Para Melhores Resultados:
1. **Use modelos maiores** (llama3.2, mistral)
2. **Fa√ßa perguntas espec√≠ficas** e detalhadas
3. **Processe mais documentos** para maior contexto
4. **Ajuste temperatura** para diferentes tipos de resposta

### Dicas de Uso:
- Perguntas abertas: "Explique o conceito de..."
- Perguntas espec√≠ficas: "Quais s√£o os 3 principais..."
- Compara√ß√µes: "Compare X com Y..."
- Listas: "Liste os principais..."

## üîó URLs Importantes

- **Interface**: http://localhost:8511
- **Ollama API**: http://localhost:11434
- **Documentos**: /home/lsantann/Documents/CC/
- **Resumos**: /home/lsantann/dev/localRAGsummary/summaries/

## üìù Logs e Monitoramento

```bash
# Ver logs do Ollama
journalctl -u ollama -f

# Ver logs da interface
tail -f /tmp/streamlit.log

# Monitorar uso de mem√≥ria
htop | grep ollama
```

---

**üéØ Resultado**: Interface completa com sele√ß√£o de modelo e integra√ß√£o Ollama para respostas de alta qualidade!
