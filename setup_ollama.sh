#!/bin/bash

echo "ðŸ¤– Configurando Sistema RAG com Ollama"
echo "======================================"

# Verificar se Ollama estÃ¡ instalado
if ! command -v ollama &> /dev/null; then
    echo "ðŸ“¥ Instalando Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
else
    echo "âœ… Ollama jÃ¡ estÃ¡ instalado"
fi

# Verificar se o servidor estÃ¡ rodando
if ! curl -s http://localhost:11434/api/tags &> /dev/null; then
    echo "ðŸš€ Iniciando servidor Ollama..."
    ollama serve &
    sleep 3
fi

# Baixar modelos recomendados
echo "ðŸ“¦ Baixando modelos recomendados..."

echo "Baixando Llama 3.2 (recomendado)..."
ollama pull llama3.2

echo "Baixando Mistral 7B (alternativa)..."
ollama pull mistral

echo "Baixando Code Llama (para cÃ³digo)..."
ollama pull codellama

# Verificar modelos disponÃ­veis
echo "ðŸ“‹ Modelos disponÃ­veis:"
ollama list

echo ""
echo "ðŸŽ‰ ConfiguraÃ§Ã£o concluÃ­da!"
echo ""
echo "Para iniciar a interface:"
echo "cd /home/lsantann/dev/localRAGsummary"
echo "source venv/bin/activate"
echo "streamlit run interface_ollama.py --server.port 8511"
echo ""
echo "Acesse: http://localhost:8511"
