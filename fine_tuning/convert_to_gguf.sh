#!/bin/bash
"""
Script para converter modelo fine-tuned para GGUF
Execute apÃ³s o fine-tuning
"""

# Instalar dependÃªncias
pip install llama.cpp

# Converter para GGUF
python -m llama_cpp.llama_convert_hf_to_gguf \
    --outfile modelo_customizado.gguf \
    --outtype f16 \
    --model-dir lora_model

echo "âœ… ConversÃ£o concluÃ­da!"
echo "ğŸ“ Arquivo GGUF: modelo_customizado.gguf"
